[example_movies_full_creategraph_01_plain]
action.email.show_password = 1
action.email.useNSSubject = 1
action.webhook.enable_allowlist = 0
alert.track = 0
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = graphee
request.ui_dispatch_view = search
search = | inputlookup movies_full_splunk.csv\
| eval rel_ref = "r" . rel_src_node . "-" . rel_dst_node \
| table obj_type, node_ref, node_label, rel_ref, rel_type, rel_src_node, rel_dst_node, prop:* \
| sort 0 obj_type, -node_label\
``` | creategraph uri=myuri account=myaccount noact=f mode="merge" propsprefix="prop:" inputformat="plain"```

[example_movies_full_creategraph_02_json]
action.email.show_password = 1
action.email.useNSSubject = 1
action.webhook.enable_allowlist = 0
alert.track = 0
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = graphee
request.ui_dispatch_view = search
search = | inputlookup movies_full_splunk.csv\
| eval rel_ref = "r" . rel_src_node . "-" . rel_dst_node \
| table obj_type, node_ref, node_label, rel_ref, rel_type, rel_src_node, rel_dst_node, prop:* \
| rename prop:* as p_*\
| tojson output_field=jsonobj\
| sort 0 obj_type, -node_label\
| fields jsonobj\
``` | creategraph uri=myuri account=myaccount noact=f mode="merge" propsprefix="p_" inputformat="json" inputfield="jsonobj" ```

[example_cypher_query_allgraphobjects_01]
action.email.show_password = 1
action.email.useNSSubject = 1
action.webhook.enable_allowlist = 0
alert.track = 0
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = graphee
request.ui_dispatch_view = search
search = | cypher uri=myuri account=myaccount noact=f query="match (n) return ID(n), labels(n), properties(n)"\
| table _raw\
| spath input=_raw

[example_getfullgraph_query_allgraphobjects_01]
action.email.show_password = 1
action.email.useNSSubject = 1
action.webhook.enable_allowlist = 0
alert.track = 0
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = graphee
request.ui_dispatch_view = search
search = | getfullgraph uri=<my_uri_id> account=<my_account_id> noact=f\
| table obj_type, node_id, node_labels, rel_id, rel_type, prop:* \
| sort 0 obj_type, -node_label, rel_type

[example_firewalltraffic_transformToJson_01]
action.email.show_password = 1
action.email.useNSSubject = 1
action.webhook.enable_allowlist = 0
alert.track = 0
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = graphee
request.ui_dispatch_view = search
search = | inputlookup graphee_demo_concepts_firewall_traffic.csv \
| rex field=dst_ip mode=sed "s/^d+\.d+\.d+\./10.10.10./g" \
| search NOT dst_ip = 10.10.10.0 NOT src_ip=0.* \
| rename dest_port as dst_port \
| table _time, src_ip, src_port, dst_ip, dst_port, bytes_received, bytes_sent, packets_received, packets_sent \
``` base data above ``` \
\
``` get all the fields ready for what we want to see in the graph: Which src ips connect to our hosted systems and services? ``` \
``` we have src and dst nodes in this firewall dataset ``` \
``` Let's say we relate the src ips to dst ips via their connection and tag some intensity properties (count connections, transfered bytes, packets) to this relationship (rel) ``` \
``` so we can now reduce the dataset via a |stats to this data ```  \
| eval conn_bytes = bytes_received + bytes_sent\
| eval conn_packets = packets_received + packets_sent\
| stats sum(conn_bytes) as sum_conn_bytes, sum(conn_packets) as sum_conn_packets, count as count_conn by src_ip, dst_ip, dst_port\
| eval rel_type = "connects_to"\
``` Our sources are the src_ip. We need a key for it. Let it just be the src_ip. That suffices (in regards of uniqueness) for that demo. Our key will go into the field src_node_ref.  \
    Neo4j requires us to prefix a variable like node_id with a word char. We use "n" here. And we add a fake hostname, to demo node properties in the json transform below. ``` \
| eval src_node_ref = "n" . src_ip \
| rex mode=sed field=src_node_ref "s/[\.\/:]/_/g"  \
| eval src_node_label = "ip" \
| eval src_hostname = src_ip . ".example.com" \
``` And we have our destination services and need key for them: dst_node_ref. We describe the destination service with the triple dst_ip, dst_port and protocol (this one is not present on the dataset and we fake it below).  \
    We alse use "n" to prefix node_id again. And we also add a fake hostname. ``` \
| eval dst_proto = "tcp" \
| eval dst_node_ref = "n" . dst_ip . ":" . dst_port . "/" . dst_proto \
| rex mode=sed field=dst_node_ref "s/[\.\/:]/_/g"  \
| eval dst_node_label = "service" \
| eval dst_hostname = dst_ip . ".internal.local" \
``` create a unique key for the rels as well, for deduplicating later on. ``` \
| eval rel_ref = "r" . src_node_ref . "-" . dst_node_ref\
\
``` With the SPL above we now have all required fields ready for our graph. But those many fields are awkward to handle. Throwing them around, transforming them into a serial stream of nodes and rels is not fun to do or maintain.\
    To solve that, the following approach is proposed: Let us understand our dataset as objects. We have three objects: src and dst nodes and rels. \
    The solution is to zip the fields of on object into a json blob and handle it in that form. We can use the awesome command |tojson (since v8.2.6) and |fromjson (since v9.0.0) Splunk introduced lately to achieve this easily. ``` \
| eval obj_type = "node" \
``` transform src \
| eval src_node = json_object( "obj_type", obj_type, "node_ref", src_node_ref, "node_label", src_node_label, "props", json_object( "ip", src_ip, "hostname", src_hostname ) ) ``` \
| eval node_ref = src_node_ref, node_label = src_node_label, p_ip = src_ip, p_hostname = src_hostname\
 ``` | tojson output_field=src_node obj_type, node_ref, node_label, p_ip, p_hostname ``` \
| eval src_node = json_object( "obj_type", obj_type, "node_ref", node_ref, "node_label", node_label, "p_ip", p_ip, "p_hostname", p_hostname )\
| fields - node_ref, node_label, p_ip, p_hostname\
``` transform dst \
| eval dst_node = json_object( "obj_type", obj_type, "node_ref", dst_node_ref, "node_label", dst_node_label, "props", json_object( "ip", dst_ip, "hostname", dst_hostname, "dst_port", dst_port, "dst_proto", dst_proto  ) ) ``` \
| eval node_ref = dst_node_ref, node_label = dst_node_label, p_ip = dst_ip, p_hostname = dst_hostname, p_port = dst_port, p_proto = dst_proto\
``` | tojson output_field=dst_node obj_type, node_ref, node_label, p_ip, p_hostname‚ p_port, p_proto ```\
| eval dst_node = json_object( "obj_type", obj_type, "node_ref", node_ref, "node_label", node_label, "p_ip", p_ip, "p_hostname", p_hostname, "p_port", p_port, "p_proto", p_proto )\
| fields - node_ref node_label, p_ip, p_hostname, p_port, p_proto\
\
``` transform rel ``` \
| eval obj_type = "rel" \
``` | eval rel = json_object( "obj_type", obj_type, "rel_ref", rel_ref, "rel_type", rel_type, "rel_src_node", src_node_ref, "rel_dst_node", dst_node_ref, "props", json_object( "rel_src_node", src_node_ref, "rel_dst_node", dst_node_ref, "sum_conn_bytes", sum_conn_bytes, "sum_conn_packets", sum_conn_packets, "count_conn", count_conn  ) ) ``` \
| eval rel_src_node = src_node_ref, rel_dst_node = dst_node_ref, p_rel_src_node = src_node_ref, p_rel_dst_node = dst_node_ref, p_sum_conn_bytes = sum_conn_bytes, p_sum_conn_bytes = sum_conn_bytes, p_sum_conn_packets = sum_conn_packets, p_count_conn = count_conn\
| tojson output_field=rel obj_type rel_ref, rel_type rel_src_node, rel_dst_node‚ p_rel_src_node, p_rel_dst_node, p_sum_conn_bytes, p_sum_conn_packets, p_count_conn\
| eval rel = json_object( "obj_type", obj_type, "rel_ref", rel_ref, "rel_type", rel_type, "rel_src_node", src_node_ref, "rel_dst_node", dst_node_ref, "p_rel_src_node", p_rel_src_node, "p_rel_dst_node", p_rel_dst_node, "p_sum_conn_bytes", p_sum_conn_bytes, "p_sum_conn_packets", p_sum_conn_packets, "p_count_conn", p_count_conn )\
| fields - rel_src_node, rel_dst_node, p_rel_src_node, p_rel_dst_node, p_sum_conn_bytes, p_sum_conn_packetsl, p_count_conn\
\
| fields src_node, dst_node, rel

[example_firewalltraffic_json_creategraph_01]
action.email.show_password = 1
action.email.useNSSubject = 1
action.webhook.enable_allowlist = 0
alert.track = 0
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = graphee
request.ui_dispatch_view = search
search = | savedsearch example_firewalltraffic_transformToJson_01\
\
``` To transform our multi-column dataset into a flat single-column table we use the following approach:\
    We need to expand each line by the number of contained objects. Using |stats is a stable way command for this purpose.\
    If we provide the by clause of |stats with multivalue field, it will behave as a duplicator for each event. \
    To achieve this, first we uniquely identify each line with a key with the following |streamstats:  ```\
| streamstats count as evtId\
``` In the duplicator multivalue field we simply put how many objects we have in each line, essentially instructing |stats to create so many duplicates of each line.   ```\
| eval expander = mvappend( "src", "dst", "rel" )\
``` both evtId, expander are used as by clause for |stats. This will create 3 identical copies of each line. ```\
| stats first(src_node) as src_node, first(dst_node) as dst_node, first(rel) as rel by evtId, expander\
``` with this most work is done. The multi-column dataset is expanded and can now carry each node and rel on a single line. ```\
\
``` next we remove the unneeded duplicates.  ```\
| eval src_node = if( expander == "src", src_node, null() )\
| eval dst_node = if( expander == "dst", dst_node, null() )\
| eval rel      = if( expander == "rel", rel,      null() )\
``` manually tidy up the field names. This is crude, as there is no SPL command that allows in-json field renames, but practical enough for this demo. ```\
| rex mode=sed field=src_node "s/\"src_/\"/g"\
| rex mode=sed field=dst_node "s/\"dst_/\"/g"\
| rex mode=sed field=rel      "s/\"rel_props/\"props/g"\
``` flatten the list into a single column ```\
| eval json_obj = coalesce( src_node, dst_node, rel )\
| fields - evtId, expander, src_node, dst_node, rel\
``` done. we now have an expanded, flatten nodes and rels dataset. ```\
\
``` use myLimit to create less objects on the neo4j instance and have the command finish faster.```\
| streamstats count as evtId\
| eval objsPerRow = 3\
| eval myLimit = 5\
| eval overallLimit = objsPerRow * myLimit\
| where evtId <= overallLimit\
\
``` do not forget that nodes need to be created before rels. this is achieved by sorting nodes to the beginning of the the dataset. otherwise the |creategraph commands error upon trying to create rels for non-existing nodes.  ```\
| spath input=json_obj obj_type \
| sort 0 obj_type\
| fields json_obj\
| dedup json_obj ```quickhack``` \
\
``` | creategraph uri=myuri account=myaccount noact=f mode="merge" propsprefix="p_" inputformat="json" inputfield="json_obj" ```
